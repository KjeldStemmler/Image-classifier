{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fxpmath import Fxp\n",
    "import copy\n",
    "import math\n",
    "import itertools as iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for quantizing a numpy array\n",
    "def quantisation(inputArray, bitSize, fractBits = 0):\n",
    "     #compute scale and zeroPoint\n",
    "    maximum = np.max(inputArray);\n",
    "    minimum = np.min(inputArray);\n",
    "    valueRange = maximum - minimum;\n",
    "    \n",
    "    #using a fxpMath dummy to get the bounds for quantisation\n",
    "    fxDummy = Fxp(1,signed = (minimum < 0), n_word = bitSize, n_frac = fractBits)\n",
    "    maxFpVal = fxDummy.upper\n",
    "    minFpVal = fxDummy.lower\n",
    "\n",
    "    #scale = 1 when only one value is present to avoid division by 0\n",
    "    scale = 1;\n",
    "    if (valueRange != 0):\n",
    "        scale = (maxFpVal - minFpVal) / valueRange;\n",
    "    zeroPoint = minFpVal-(scale*minimum);\n",
    "    \n",
    "    #the actual quantisation and restructuring into a fxp-array\n",
    "    output = Fxp((inputArray * scale) + zeroPoint, (minimum < 0), bitSize, fractBits)\n",
    "\n",
    "    return output;\n",
    "\n",
    "def fixedPointConversion(inputArray, bitSize, fractBits = 0):\n",
    "    output = Fxp(inputArray, signed= True, n_word = bitSize, n_frac = fractBits)\n",
    "    return (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 15, 15, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124330 (485.66 KB)\n",
      "Trainable params: 124330 (485.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5971 - accuracy: 0.4109 - val_loss: 1.2662 - val_accuracy: 0.5500\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2165 - accuracy: 0.5665 - val_loss: 1.1596 - val_accuracy: 0.5877\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0675 - accuracy: 0.6219 - val_loss: 0.9790 - val_accuracy: 0.6583\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9603 - accuracy: 0.6607 - val_loss: 0.9041 - val_accuracy: 0.6805\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8969 - accuracy: 0.6852 - val_loss: 0.9272 - val_accuracy: 0.6786\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8528 - accuracy: 0.6995 - val_loss: 0.8741 - val_accuracy: 0.6979\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8142 - accuracy: 0.7141 - val_loss: 0.8999 - val_accuracy: 0.6937\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7748 - accuracy: 0.7266 - val_loss: 0.8479 - val_accuracy: 0.7061\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7424 - accuracy: 0.7393 - val_loss: 0.8015 - val_accuracy: 0.7259\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7184 - accuracy: 0.7472 - val_loss: 0.7765 - val_accuracy: 0.7335\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6921 - accuracy: 0.7567 - val_loss: 0.7816 - val_accuracy: 0.7329\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6770 - accuracy: 0.7623 - val_loss: 0.8565 - val_accuracy: 0.7143\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6620 - accuracy: 0.7673 - val_loss: 0.7725 - val_accuracy: 0.7404\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6406 - accuracy: 0.7756 - val_loss: 0.7722 - val_accuracy: 0.7377\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6253 - accuracy: 0.7796 - val_loss: 0.8081 - val_accuracy: 0.7268\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6079 - accuracy: 0.7868 - val_loss: 0.7677 - val_accuracy: 0.7398\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5964 - accuracy: 0.7895 - val_loss: 0.7911 - val_accuracy: 0.7379\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5864 - accuracy: 0.7924 - val_loss: 0.8294 - val_accuracy: 0.7266\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5775 - accuracy: 0.7975 - val_loss: 0.7867 - val_accuracy: 0.7392\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5602 - accuracy: 0.8024 - val_loss: 0.7827 - val_accuracy: 0.7366\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.7827 - accuracy: 0.7366 - 652ms/epoch - 2ms/step\n",
      "0.7365999817848206\n"
     ]
    }
   ],
   "source": [
    "(trainingImages, trainingLabels), (testImages, testLabels) = cifar10.load_data()\n",
    "\n",
    "#normalizing the values to 0-1\n",
    "trainingImages = trainingImages / 255.0\n",
    "testImages = testImages / 255.0\n",
    "\n",
    "# One hot encoding the target class (labels)\n",
    "num_classes = 10\n",
    "trainingLabels = tf.keras.utils.to_categorical(trainingLabels, num_classes)\n",
    "testLabels = tf.keras.utils.to_categorical(testLabels, num_classes)\n",
    "\n",
    "#convolution layers for feature extraction\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "\n",
    "#fully connected layers for class prediction\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#print the current model summary\n",
    "model.summary()\n",
    "\n",
    "#preparing model for training\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "history = model.fit(trainingImages, trainingLabels, epochs=20, \n",
    "                    validation_data=(testImages, testLabels))\n",
    "\n",
    "#set to True to display the changing accuracy of the model during training\n",
    "if(True):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "#display the accuracy of the trained model\n",
    "test_loss, test_acc = model.evaluate(testImages,  testLabels, verbose=2)\n",
    "print(test_acc)\n",
    "\n",
    "#get the weights of the model \n",
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_classifier\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_classifier\\assets\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model.save(\"trained_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "model = tf.keras.models.load_model(\"trained_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6, 9, 10, 11]\n",
      "[1, 0, 0, 2, 0, 0, 2, 0, 0, 1, 1, 1]\n",
      "729\n",
      "[(2, 2, 2, 2, 2, 2), (2, 2, 2, 2, 2, 4), (2, 2, 2, 2, 2, 8), (2, 2, 2, 2, 4, 2), (2, 2, 2, 2, 4, 4), (2, 2, 2, 2, 4, 8), (2, 2, 2, 2, 8, 2), (2, 2, 2, 2, 8, 4), (2, 2, 2, 2, 8, 8), (2, 2, 2, 4, 2, 2), (2, 2, 2, 4, 2, 4), (2, 2, 2, 4, 2, 8), (2, 2, 2, 4, 4, 2), (2, 2, 2, 4, 4, 4), (2, 2, 2, 4, 4, 8), (2, 2, 2, 4, 8, 2), (2, 2, 2, 4, 8, 4), (2, 2, 2, 4, 8, 8), (2, 2, 2, 8, 2, 2), (2, 2, 2, 8, 2, 4), (2, 2, 2, 8, 2, 8), (2, 2, 2, 8, 4, 2), (2, 2, 2, 8, 4, 4), (2, 2, 2, 8, 4, 8), (2, 2, 2, 8, 8, 2), (2, 2, 2, 8, 8, 4), (2, 2, 2, 8, 8, 8), (2, 2, 4, 2, 2, 2), (2, 2, 4, 2, 2, 4), (2, 2, 4, 2, 2, 8), (2, 2, 4, 2, 4, 2), (2, 2, 4, 2, 4, 4), (2, 2, 4, 2, 4, 8), (2, 2, 4, 2, 8, 2), (2, 2, 4, 2, 8, 4), (2, 2, 4, 2, 8, 8), (2, 2, 4, 4, 2, 2), (2, 2, 4, 4, 2, 4), (2, 2, 4, 4, 2, 8), (2, 2, 4, 4, 4, 2), (2, 2, 4, 4, 4, 4), (2, 2, 4, 4, 4, 8), (2, 2, 4, 4, 8, 2), (2, 2, 4, 4, 8, 4), (2, 2, 4, 4, 8, 8), (2, 2, 4, 8, 2, 2), (2, 2, 4, 8, 2, 4), (2, 2, 4, 8, 2, 8), (2, 2, 4, 8, 4, 2), (2, 2, 4, 8, 4, 4), (2, 2, 4, 8, 4, 8), (2, 2, 4, 8, 8, 2), (2, 2, 4, 8, 8, 4), (2, 2, 4, 8, 8, 8), (2, 2, 8, 2, 2, 2), (2, 2, 8, 2, 2, 4), (2, 2, 8, 2, 2, 8), (2, 2, 8, 2, 4, 2), (2, 2, 8, 2, 4, 4), (2, 2, 8, 2, 4, 8), (2, 2, 8, 2, 8, 2), (2, 2, 8, 2, 8, 4), (2, 2, 8, 2, 8, 8), (2, 2, 8, 4, 2, 2), (2, 2, 8, 4, 2, 4), (2, 2, 8, 4, 2, 8), (2, 2, 8, 4, 4, 2), (2, 2, 8, 4, 4, 4), (2, 2, 8, 4, 4, 8), (2, 2, 8, 4, 8, 2), (2, 2, 8, 4, 8, 4), (2, 2, 8, 4, 8, 8), (2, 2, 8, 8, 2, 2), (2, 2, 8, 8, 2, 4), (2, 2, 8, 8, 2, 8), (2, 2, 8, 8, 4, 2), (2, 2, 8, 8, 4, 4), (2, 2, 8, 8, 4, 8), (2, 2, 8, 8, 8, 2), (2, 2, 8, 8, 8, 4), (2, 2, 8, 8, 8, 8), (2, 4, 2, 2, 2, 2), (2, 4, 2, 2, 2, 4), (2, 4, 2, 2, 2, 8), (2, 4, 2, 2, 4, 2), (2, 4, 2, 2, 4, 4), (2, 4, 2, 2, 4, 8), (2, 4, 2, 2, 8, 2), (2, 4, 2, 2, 8, 4), (2, 4, 2, 2, 8, 8), (2, 4, 2, 4, 2, 2), (2, 4, 2, 4, 2, 4), (2, 4, 2, 4, 2, 8), (2, 4, 2, 4, 4, 2), (2, 4, 2, 4, 4, 4), (2, 4, 2, 4, 4, 8), (2, 4, 2, 4, 8, 2), (2, 4, 2, 4, 8, 4), (2, 4, 2, 4, 8, 8), (2, 4, 2, 8, 2, 2), (2, 4, 2, 8, 2, 4), (2, 4, 2, 8, 2, 8), (2, 4, 2, 8, 4, 2), (2, 4, 2, 8, 4, 4), (2, 4, 2, 8, 4, 8), (2, 4, 2, 8, 8, 2), (2, 4, 2, 8, 8, 4), (2, 4, 2, 8, 8, 8), (2, 4, 4, 2, 2, 2), (2, 4, 4, 2, 2, 4), (2, 4, 4, 2, 2, 8), (2, 4, 4, 2, 4, 2), (2, 4, 4, 2, 4, 4), (2, 4, 4, 2, 4, 8), (2, 4, 4, 2, 8, 2), (2, 4, 4, 2, 8, 4), (2, 4, 4, 2, 8, 8), (2, 4, 4, 4, 2, 2), (2, 4, 4, 4, 2, 4), (2, 4, 4, 4, 2, 8), (2, 4, 4, 4, 4, 2), (2, 4, 4, 4, 4, 4), (2, 4, 4, 4, 4, 8), (2, 4, 4, 4, 8, 2), (2, 4, 4, 4, 8, 4), (2, 4, 4, 4, 8, 8), (2, 4, 4, 8, 2, 2), (2, 4, 4, 8, 2, 4), (2, 4, 4, 8, 2, 8), (2, 4, 4, 8, 4, 2), (2, 4, 4, 8, 4, 4), (2, 4, 4, 8, 4, 8), (2, 4, 4, 8, 8, 2), (2, 4, 4, 8, 8, 4), (2, 4, 4, 8, 8, 8), (2, 4, 8, 2, 2, 2), (2, 4, 8, 2, 2, 4), (2, 4, 8, 2, 2, 8), (2, 4, 8, 2, 4, 2), (2, 4, 8, 2, 4, 4), (2, 4, 8, 2, 4, 8), (2, 4, 8, 2, 8, 2), (2, 4, 8, 2, 8, 4), (2, 4, 8, 2, 8, 8), (2, 4, 8, 4, 2, 2), (2, 4, 8, 4, 2, 4), (2, 4, 8, 4, 2, 8), (2, 4, 8, 4, 4, 2), (2, 4, 8, 4, 4, 4), (2, 4, 8, 4, 4, 8), (2, 4, 8, 4, 8, 2), (2, 4, 8, 4, 8, 4), (2, 4, 8, 4, 8, 8), (2, 4, 8, 8, 2, 2), (2, 4, 8, 8, 2, 4), (2, 4, 8, 8, 2, 8), (2, 4, 8, 8, 4, 2), (2, 4, 8, 8, 4, 4), (2, 4, 8, 8, 4, 8), (2, 4, 8, 8, 8, 2), (2, 4, 8, 8, 8, 4), (2, 4, 8, 8, 8, 8), (2, 8, 2, 2, 2, 2), (2, 8, 2, 2, 2, 4), (2, 8, 2, 2, 2, 8), (2, 8, 2, 2, 4, 2), (2, 8, 2, 2, 4, 4), (2, 8, 2, 2, 4, 8), (2, 8, 2, 2, 8, 2), (2, 8, 2, 2, 8, 4), (2, 8, 2, 2, 8, 8), (2, 8, 2, 4, 2, 2), (2, 8, 2, 4, 2, 4), (2, 8, 2, 4, 2, 8), (2, 8, 2, 4, 4, 2), (2, 8, 2, 4, 4, 4), (2, 8, 2, 4, 4, 8), (2, 8, 2, 4, 8, 2), (2, 8, 2, 4, 8, 4), (2, 8, 2, 4, 8, 8), (2, 8, 2, 8, 2, 2), (2, 8, 2, 8, 2, 4), (2, 8, 2, 8, 2, 8), (2, 8, 2, 8, 4, 2), (2, 8, 2, 8, 4, 4), (2, 8, 2, 8, 4, 8), (2, 8, 2, 8, 8, 2), (2, 8, 2, 8, 8, 4), (2, 8, 2, 8, 8, 8), (2, 8, 4, 2, 2, 2), (2, 8, 4, 2, 2, 4), (2, 8, 4, 2, 2, 8), (2, 8, 4, 2, 4, 2), (2, 8, 4, 2, 4, 4), (2, 8, 4, 2, 4, 8), (2, 8, 4, 2, 8, 2), (2, 8, 4, 2, 8, 4), (2, 8, 4, 2, 8, 8), (2, 8, 4, 4, 2, 2), (2, 8, 4, 4, 2, 4), (2, 8, 4, 4, 2, 8), (2, 8, 4, 4, 4, 2), (2, 8, 4, 4, 4, 4), (2, 8, 4, 4, 4, 8), (2, 8, 4, 4, 8, 2), (2, 8, 4, 4, 8, 4), (2, 8, 4, 4, 8, 8), (2, 8, 4, 8, 2, 2), (2, 8, 4, 8, 2, 4), (2, 8, 4, 8, 2, 8), (2, 8, 4, 8, 4, 2), (2, 8, 4, 8, 4, 4), (2, 8, 4, 8, 4, 8), (2, 8, 4, 8, 8, 2), (2, 8, 4, 8, 8, 4), (2, 8, 4, 8, 8, 8), (2, 8, 8, 2, 2, 2), (2, 8, 8, 2, 2, 4), (2, 8, 8, 2, 2, 8), (2, 8, 8, 2, 4, 2), (2, 8, 8, 2, 4, 4), (2, 8, 8, 2, 4, 8), (2, 8, 8, 2, 8, 2), (2, 8, 8, 2, 8, 4), (2, 8, 8, 2, 8, 8), (2, 8, 8, 4, 2, 2), (2, 8, 8, 4, 2, 4), (2, 8, 8, 4, 2, 8), (2, 8, 8, 4, 4, 2), (2, 8, 8, 4, 4, 4), (2, 8, 8, 4, 4, 8), (2, 8, 8, 4, 8, 2), (2, 8, 8, 4, 8, 4), (2, 8, 8, 4, 8, 8), (2, 8, 8, 8, 2, 2), (2, 8, 8, 8, 2, 4), (2, 8, 8, 8, 2, 8), (2, 8, 8, 8, 4, 2), (2, 8, 8, 8, 4, 4), (2, 8, 8, 8, 4, 8), (2, 8, 8, 8, 8, 2), (2, 8, 8, 8, 8, 4), (2, 8, 8, 8, 8, 8), (4, 2, 2, 2, 2, 2), (4, 2, 2, 2, 2, 4), (4, 2, 2, 2, 2, 8), (4, 2, 2, 2, 4, 2), (4, 2, 2, 2, 4, 4), (4, 2, 2, 2, 4, 8), (4, 2, 2, 2, 8, 2), (4, 2, 2, 2, 8, 4), (4, 2, 2, 2, 8, 8), (4, 2, 2, 4, 2, 2), (4, 2, 2, 4, 2, 4), (4, 2, 2, 4, 2, 8), (4, 2, 2, 4, 4, 2), (4, 2, 2, 4, 4, 4), (4, 2, 2, 4, 4, 8), (4, 2, 2, 4, 8, 2), (4, 2, 2, 4, 8, 4), (4, 2, 2, 4, 8, 8), (4, 2, 2, 8, 2, 2), (4, 2, 2, 8, 2, 4), (4, 2, 2, 8, 2, 8), (4, 2, 2, 8, 4, 2), (4, 2, 2, 8, 4, 4), (4, 2, 2, 8, 4, 8), (4, 2, 2, 8, 8, 2), (4, 2, 2, 8, 8, 4), (4, 2, 2, 8, 8, 8), (4, 2, 4, 2, 2, 2), (4, 2, 4, 2, 2, 4), (4, 2, 4, 2, 2, 8), (4, 2, 4, 2, 4, 2), (4, 2, 4, 2, 4, 4), (4, 2, 4, 2, 4, 8), (4, 2, 4, 2, 8, 2), (4, 2, 4, 2, 8, 4), (4, 2, 4, 2, 8, 8), (4, 2, 4, 4, 2, 2), (4, 2, 4, 4, 2, 4), (4, 2, 4, 4, 2, 8), (4, 2, 4, 4, 4, 2), (4, 2, 4, 4, 4, 4), (4, 2, 4, 4, 4, 8), (4, 2, 4, 4, 8, 2), (4, 2, 4, 4, 8, 4), (4, 2, 4, 4, 8, 8), (4, 2, 4, 8, 2, 2), (4, 2, 4, 8, 2, 4), (4, 2, 4, 8, 2, 8), (4, 2, 4, 8, 4, 2), (4, 2, 4, 8, 4, 4), (4, 2, 4, 8, 4, 8), (4, 2, 4, 8, 8, 2), (4, 2, 4, 8, 8, 4), (4, 2, 4, 8, 8, 8), (4, 2, 8, 2, 2, 2), (4, 2, 8, 2, 2, 4), (4, 2, 8, 2, 2, 8), (4, 2, 8, 2, 4, 2), (4, 2, 8, 2, 4, 4), (4, 2, 8, 2, 4, 8), (4, 2, 8, 2, 8, 2), (4, 2, 8, 2, 8, 4), (4, 2, 8, 2, 8, 8), (4, 2, 8, 4, 2, 2), (4, 2, 8, 4, 2, 4), (4, 2, 8, 4, 2, 8), (4, 2, 8, 4, 4, 2), (4, 2, 8, 4, 4, 4), (4, 2, 8, 4, 4, 8), (4, 2, 8, 4, 8, 2), (4, 2, 8, 4, 8, 4), (4, 2, 8, 4, 8, 8), (4, 2, 8, 8, 2, 2), (4, 2, 8, 8, 2, 4), (4, 2, 8, 8, 2, 8), (4, 2, 8, 8, 4, 2), (4, 2, 8, 8, 4, 4), (4, 2, 8, 8, 4, 8), (4, 2, 8, 8, 8, 2), (4, 2, 8, 8, 8, 4), (4, 2, 8, 8, 8, 8), (4, 4, 2, 2, 2, 2), (4, 4, 2, 2, 2, 4), (4, 4, 2, 2, 2, 8), (4, 4, 2, 2, 4, 2), (4, 4, 2, 2, 4, 4), (4, 4, 2, 2, 4, 8), (4, 4, 2, 2, 8, 2), (4, 4, 2, 2, 8, 4), (4, 4, 2, 2, 8, 8), (4, 4, 2, 4, 2, 2), (4, 4, 2, 4, 2, 4), (4, 4, 2, 4, 2, 8), (4, 4, 2, 4, 4, 2), (4, 4, 2, 4, 4, 4), (4, 4, 2, 4, 4, 8), (4, 4, 2, 4, 8, 2), (4, 4, 2, 4, 8, 4), (4, 4, 2, 4, 8, 8), (4, 4, 2, 8, 2, 2), (4, 4, 2, 8, 2, 4), (4, 4, 2, 8, 2, 8), (4, 4, 2, 8, 4, 2), (4, 4, 2, 8, 4, 4), (4, 4, 2, 8, 4, 8), (4, 4, 2, 8, 8, 2), (4, 4, 2, 8, 8, 4), (4, 4, 2, 8, 8, 8), (4, 4, 4, 2, 2, 2), (4, 4, 4, 2, 2, 4), (4, 4, 4, 2, 2, 8), (4, 4, 4, 2, 4, 2), (4, 4, 4, 2, 4, 4), (4, 4, 4, 2, 4, 8), (4, 4, 4, 2, 8, 2), (4, 4, 4, 2, 8, 4), (4, 4, 4, 2, 8, 8), (4, 4, 4, 4, 2, 2), (4, 4, 4, 4, 2, 4), (4, 4, 4, 4, 2, 8), (4, 4, 4, 4, 4, 2), (4, 4, 4, 4, 4, 4), (4, 4, 4, 4, 4, 8), (4, 4, 4, 4, 8, 2), (4, 4, 4, 4, 8, 4), (4, 4, 4, 4, 8, 8), (4, 4, 4, 8, 2, 2), (4, 4, 4, 8, 2, 4), (4, 4, 4, 8, 2, 8), (4, 4, 4, 8, 4, 2), (4, 4, 4, 8, 4, 4), (4, 4, 4, 8, 4, 8), (4, 4, 4, 8, 8, 2), (4, 4, 4, 8, 8, 4), (4, 4, 4, 8, 8, 8), (4, 4, 8, 2, 2, 2), (4, 4, 8, 2, 2, 4), (4, 4, 8, 2, 2, 8), (4, 4, 8, 2, 4, 2), (4, 4, 8, 2, 4, 4), (4, 4, 8, 2, 4, 8), (4, 4, 8, 2, 8, 2), (4, 4, 8, 2, 8, 4), (4, 4, 8, 2, 8, 8), (4, 4, 8, 4, 2, 2), (4, 4, 8, 4, 2, 4), (4, 4, 8, 4, 2, 8), (4, 4, 8, 4, 4, 2), (4, 4, 8, 4, 4, 4), (4, 4, 8, 4, 4, 8), (4, 4, 8, 4, 8, 2), (4, 4, 8, 4, 8, 4), (4, 4, 8, 4, 8, 8), (4, 4, 8, 8, 2, 2), (4, 4, 8, 8, 2, 4), (4, 4, 8, 8, 2, 8), (4, 4, 8, 8, 4, 2), (4, 4, 8, 8, 4, 4), (4, 4, 8, 8, 4, 8), (4, 4, 8, 8, 8, 2), (4, 4, 8, 8, 8, 4), (4, 4, 8, 8, 8, 8), (4, 8, 2, 2, 2, 2), (4, 8, 2, 2, 2, 4), (4, 8, 2, 2, 2, 8), (4, 8, 2, 2, 4, 2), (4, 8, 2, 2, 4, 4), (4, 8, 2, 2, 4, 8), (4, 8, 2, 2, 8, 2), (4, 8, 2, 2, 8, 4), (4, 8, 2, 2, 8, 8), (4, 8, 2, 4, 2, 2), (4, 8, 2, 4, 2, 4), (4, 8, 2, 4, 2, 8), (4, 8, 2, 4, 4, 2), (4, 8, 2, 4, 4, 4), (4, 8, 2, 4, 4, 8), (4, 8, 2, 4, 8, 2), (4, 8, 2, 4, 8, 4), (4, 8, 2, 4, 8, 8), (4, 8, 2, 8, 2, 2), (4, 8, 2, 8, 2, 4), (4, 8, 2, 8, 2, 8), (4, 8, 2, 8, 4, 2), (4, 8, 2, 8, 4, 4), (4, 8, 2, 8, 4, 8), (4, 8, 2, 8, 8, 2), (4, 8, 2, 8, 8, 4), (4, 8, 2, 8, 8, 8), (4, 8, 4, 2, 2, 2), (4, 8, 4, 2, 2, 4), (4, 8, 4, 2, 2, 8), (4, 8, 4, 2, 4, 2), (4, 8, 4, 2, 4, 4), (4, 8, 4, 2, 4, 8), (4, 8, 4, 2, 8, 2), (4, 8, 4, 2, 8, 4), (4, 8, 4, 2, 8, 8), (4, 8, 4, 4, 2, 2), (4, 8, 4, 4, 2, 4), (4, 8, 4, 4, 2, 8), (4, 8, 4, 4, 4, 2), (4, 8, 4, 4, 4, 4), (4, 8, 4, 4, 4, 8), (4, 8, 4, 4, 8, 2), (4, 8, 4, 4, 8, 4), (4, 8, 4, 4, 8, 8), (4, 8, 4, 8, 2, 2), (4, 8, 4, 8, 2, 4), (4, 8, 4, 8, 2, 8), (4, 8, 4, 8, 4, 2), (4, 8, 4, 8, 4, 4), (4, 8, 4, 8, 4, 8), (4, 8, 4, 8, 8, 2), (4, 8, 4, 8, 8, 4), (4, 8, 4, 8, 8, 8), (4, 8, 8, 2, 2, 2), (4, 8, 8, 2, 2, 4), (4, 8, 8, 2, 2, 8), (4, 8, 8, 2, 4, 2), (4, 8, 8, 2, 4, 4), (4, 8, 8, 2, 4, 8), (4, 8, 8, 2, 8, 2), (4, 8, 8, 2, 8, 4), (4, 8, 8, 2, 8, 8), (4, 8, 8, 4, 2, 2), (4, 8, 8, 4, 2, 4), (4, 8, 8, 4, 2, 8), (4, 8, 8, 4, 4, 2), (4, 8, 8, 4, 4, 4), (4, 8, 8, 4, 4, 8), (4, 8, 8, 4, 8, 2), (4, 8, 8, 4, 8, 4), (4, 8, 8, 4, 8, 8), (4, 8, 8, 8, 2, 2), (4, 8, 8, 8, 2, 4), (4, 8, 8, 8, 2, 8), (4, 8, 8, 8, 4, 2), (4, 8, 8, 8, 4, 4), (4, 8, 8, 8, 4, 8), (4, 8, 8, 8, 8, 2), (4, 8, 8, 8, 8, 4), (4, 8, 8, 8, 8, 8), (8, 2, 2, 2, 2, 2), (8, 2, 2, 2, 2, 4), (8, 2, 2, 2, 2, 8), (8, 2, 2, 2, 4, 2), (8, 2, 2, 2, 4, 4), (8, 2, 2, 2, 4, 8), (8, 2, 2, 2, 8, 2), (8, 2, 2, 2, 8, 4), (8, 2, 2, 2, 8, 8), (8, 2, 2, 4, 2, 2), (8, 2, 2, 4, 2, 4), (8, 2, 2, 4, 2, 8), (8, 2, 2, 4, 4, 2), (8, 2, 2, 4, 4, 4), (8, 2, 2, 4, 4, 8), (8, 2, 2, 4, 8, 2), (8, 2, 2, 4, 8, 4), (8, 2, 2, 4, 8, 8), (8, 2, 2, 8, 2, 2), (8, 2, 2, 8, 2, 4), (8, 2, 2, 8, 2, 8), (8, 2, 2, 8, 4, 2), (8, 2, 2, 8, 4, 4), (8, 2, 2, 8, 4, 8), (8, 2, 2, 8, 8, 2), (8, 2, 2, 8, 8, 4), (8, 2, 2, 8, 8, 8), (8, 2, 4, 2, 2, 2), (8, 2, 4, 2, 2, 4), (8, 2, 4, 2, 2, 8), (8, 2, 4, 2, 4, 2), (8, 2, 4, 2, 4, 4), (8, 2, 4, 2, 4, 8), (8, 2, 4, 2, 8, 2), (8, 2, 4, 2, 8, 4), (8, 2, 4, 2, 8, 8), (8, 2, 4, 4, 2, 2), (8, 2, 4, 4, 2, 4), (8, 2, 4, 4, 2, 8), (8, 2, 4, 4, 4, 2), (8, 2, 4, 4, 4, 4), (8, 2, 4, 4, 4, 8), (8, 2, 4, 4, 8, 2), (8, 2, 4, 4, 8, 4), (8, 2, 4, 4, 8, 8), (8, 2, 4, 8, 2, 2), (8, 2, 4, 8, 2, 4), (8, 2, 4, 8, 2, 8), (8, 2, 4, 8, 4, 2), (8, 2, 4, 8, 4, 4), (8, 2, 4, 8, 4, 8), (8, 2, 4, 8, 8, 2), (8, 2, 4, 8, 8, 4), (8, 2, 4, 8, 8, 8), (8, 2, 8, 2, 2, 2), (8, 2, 8, 2, 2, 4), (8, 2, 8, 2, 2, 8), (8, 2, 8, 2, 4, 2), (8, 2, 8, 2, 4, 4), (8, 2, 8, 2, 4, 8), (8, 2, 8, 2, 8, 2), (8, 2, 8, 2, 8, 4), (8, 2, 8, 2, 8, 8), (8, 2, 8, 4, 2, 2), (8, 2, 8, 4, 2, 4), (8, 2, 8, 4, 2, 8), (8, 2, 8, 4, 4, 2), (8, 2, 8, 4, 4, 4), (8, 2, 8, 4, 4, 8), (8, 2, 8, 4, 8, 2), (8, 2, 8, 4, 8, 4), (8, 2, 8, 4, 8, 8), (8, 2, 8, 8, 2, 2), (8, 2, 8, 8, 2, 4), (8, 2, 8, 8, 2, 8), (8, 2, 8, 8, 4, 2), (8, 2, 8, 8, 4, 4), (8, 2, 8, 8, 4, 8), (8, 2, 8, 8, 8, 2), (8, 2, 8, 8, 8, 4), (8, 2, 8, 8, 8, 8), (8, 4, 2, 2, 2, 2), (8, 4, 2, 2, 2, 4), (8, 4, 2, 2, 2, 8), (8, 4, 2, 2, 4, 2), (8, 4, 2, 2, 4, 4), (8, 4, 2, 2, 4, 8), (8, 4, 2, 2, 8, 2), (8, 4, 2, 2, 8, 4), (8, 4, 2, 2, 8, 8), (8, 4, 2, 4, 2, 2), (8, 4, 2, 4, 2, 4), (8, 4, 2, 4, 2, 8), (8, 4, 2, 4, 4, 2), (8, 4, 2, 4, 4, 4), (8, 4, 2, 4, 4, 8), (8, 4, 2, 4, 8, 2), (8, 4, 2, 4, 8, 4), (8, 4, 2, 4, 8, 8), (8, 4, 2, 8, 2, 2), (8, 4, 2, 8, 2, 4), (8, 4, 2, 8, 2, 8), (8, 4, 2, 8, 4, 2), (8, 4, 2, 8, 4, 4), (8, 4, 2, 8, 4, 8), (8, 4, 2, 8, 8, 2), (8, 4, 2, 8, 8, 4), (8, 4, 2, 8, 8, 8), (8, 4, 4, 2, 2, 2), (8, 4, 4, 2, 2, 4), (8, 4, 4, 2, 2, 8), (8, 4, 4, 2, 4, 2), (8, 4, 4, 2, 4, 4), (8, 4, 4, 2, 4, 8), (8, 4, 4, 2, 8, 2), (8, 4, 4, 2, 8, 4), (8, 4, 4, 2, 8, 8), (8, 4, 4, 4, 2, 2), (8, 4, 4, 4, 2, 4), (8, 4, 4, 4, 2, 8), (8, 4, 4, 4, 4, 2), (8, 4, 4, 4, 4, 4), (8, 4, 4, 4, 4, 8), (8, 4, 4, 4, 8, 2), (8, 4, 4, 4, 8, 4), (8, 4, 4, 4, 8, 8), (8, 4, 4, 8, 2, 2), (8, 4, 4, 8, 2, 4), (8, 4, 4, 8, 2, 8), (8, 4, 4, 8, 4, 2), (8, 4, 4, 8, 4, 4), (8, 4, 4, 8, 4, 8), (8, 4, 4, 8, 8, 2), (8, 4, 4, 8, 8, 4), (8, 4, 4, 8, 8, 8), (8, 4, 8, 2, 2, 2), (8, 4, 8, 2, 2, 4), (8, 4, 8, 2, 2, 8), (8, 4, 8, 2, 4, 2), (8, 4, 8, 2, 4, 4), (8, 4, 8, 2, 4, 8), (8, 4, 8, 2, 8, 2), (8, 4, 8, 2, 8, 4), (8, 4, 8, 2, 8, 8), (8, 4, 8, 4, 2, 2), (8, 4, 8, 4, 2, 4), (8, 4, 8, 4, 2, 8), (8, 4, 8, 4, 4, 2), (8, 4, 8, 4, 4, 4), (8, 4, 8, 4, 4, 8), (8, 4, 8, 4, 8, 2), (8, 4, 8, 4, 8, 4), (8, 4, 8, 4, 8, 8), (8, 4, 8, 8, 2, 2), (8, 4, 8, 8, 2, 4), (8, 4, 8, 8, 2, 8), (8, 4, 8, 8, 4, 2), (8, 4, 8, 8, 4, 4), (8, 4, 8, 8, 4, 8), (8, 4, 8, 8, 8, 2), (8, 4, 8, 8, 8, 4), (8, 4, 8, 8, 8, 8), (8, 8, 2, 2, 2, 2), (8, 8, 2, 2, 2, 4), (8, 8, 2, 2, 2, 8), (8, 8, 2, 2, 4, 2), (8, 8, 2, 2, 4, 4), (8, 8, 2, 2, 4, 8), (8, 8, 2, 2, 8, 2), (8, 8, 2, 2, 8, 4), (8, 8, 2, 2, 8, 8), (8, 8, 2, 4, 2, 2), (8, 8, 2, 4, 2, 4), (8, 8, 2, 4, 2, 8), (8, 8, 2, 4, 4, 2), (8, 8, 2, 4, 4, 4), (8, 8, 2, 4, 4, 8), (8, 8, 2, 4, 8, 2), (8, 8, 2, 4, 8, 4), (8, 8, 2, 4, 8, 8), (8, 8, 2, 8, 2, 2), (8, 8, 2, 8, 2, 4), (8, 8, 2, 8, 2, 8), (8, 8, 2, 8, 4, 2), (8, 8, 2, 8, 4, 4), (8, 8, 2, 8, 4, 8), (8, 8, 2, 8, 8, 2), (8, 8, 2, 8, 8, 4), (8, 8, 2, 8, 8, 8), (8, 8, 4, 2, 2, 2), (8, 8, 4, 2, 2, 4), (8, 8, 4, 2, 2, 8), (8, 8, 4, 2, 4, 2), (8, 8, 4, 2, 4, 4), (8, 8, 4, 2, 4, 8), (8, 8, 4, 2, 8, 2), (8, 8, 4, 2, 8, 4), (8, 8, 4, 2, 8, 8), (8, 8, 4, 4, 2, 2), (8, 8, 4, 4, 2, 4), (8, 8, 4, 4, 2, 8), (8, 8, 4, 4, 4, 2), (8, 8, 4, 4, 4, 4), (8, 8, 4, 4, 4, 8), (8, 8, 4, 4, 8, 2), (8, 8, 4, 4, 8, 4), (8, 8, 4, 4, 8, 8), (8, 8, 4, 8, 2, 2), (8, 8, 4, 8, 2, 4), (8, 8, 4, 8, 2, 8), (8, 8, 4, 8, 4, 2), (8, 8, 4, 8, 4, 4), (8, 8, 4, 8, 4, 8), (8, 8, 4, 8, 8, 2), (8, 8, 4, 8, 8, 4), (8, 8, 4, 8, 8, 8), (8, 8, 8, 2, 2, 2), (8, 8, 8, 2, 2, 4), (8, 8, 8, 2, 2, 8), (8, 8, 8, 2, 4, 2), (8, 8, 8, 2, 4, 4), (8, 8, 8, 2, 4, 8), (8, 8, 8, 2, 8, 2), (8, 8, 8, 2, 8, 4), (8, 8, 8, 2, 8, 8), (8, 8, 8, 4, 2, 2), (8, 8, 8, 4, 2, 4), (8, 8, 8, 4, 2, 8), (8, 8, 8, 4, 4, 2), (8, 8, 8, 4, 4, 4), (8, 8, 8, 4, 4, 8), (8, 8, 8, 4, 8, 2), (8, 8, 8, 4, 8, 4), (8, 8, 8, 4, 8, 8), (8, 8, 8, 8, 2, 2), (8, 8, 8, 8, 2, 4), (8, 8, 8, 8, 2, 8), (8, 8, 8, 8, 4, 2), (8, 8, 8, 8, 4, 4), (8, 8, 8, 8, 4, 8), (8, 8, 8, 8, 8, 2), (8, 8, 8, 8, 8, 4), (8, 8, 8, 8, 8, 8)]\n",
      "run: 0\n",
      "0.11779999732971191\n",
      "run: 1\n",
      "0.12359999865293503\n",
      "run: 2\n",
      "0.12200000137090683\n",
      "run: 3\n",
      "0.121799997985363\n",
      "run: 4\n",
      "0.12710000574588776\n",
      "run: 5\n",
      "0.12680000066757202\n",
      "run: 6\n",
      "0.11860000342130661\n",
      "run: 7\n",
      "0.12530000507831573\n",
      "run: 8\n",
      "0.12430000305175781\n",
      "run: 9\n",
      "0.10599999874830246\n",
      "run: 10\n",
      "0.11029999703168869\n",
      "run: 11\n",
      "0.11150000244379044\n",
      "run: 12\n",
      "0.11559999734163284\n",
      "run: 13\n",
      "0.11900000274181366\n",
      "run: 14\n",
      "0.1193000003695488\n",
      "run: 15\n",
      "0.1136000007390976\n",
      "run: 16\n",
      "0.1185000017285347\n",
      "run: 17\n",
      "0.1193000003695488\n",
      "run: 18\n",
      "0.10570000112056732\n",
      "run: 19\n",
      "0.10760000348091125\n",
      "run: 20\n",
      "0.10949999839067459\n",
      "run: 21\n",
      "0.11420000344514847\n",
      "run: 22\n",
      "0.11800000071525574\n",
      "run: 23\n",
      "0.11959999799728394\n",
      "run: 24\n",
      "0.11309999972581863\n",
      "run: 25\n",
      "0.11789999902248383\n",
      "run: 26\n",
      "0.11869999766349792\n",
      "run: 27\n",
      "0.10970000177621841\n",
      "run: 28\n",
      "0.1096000000834465\n",
      "run: 29\n",
      "0.10790000110864639\n",
      "run: 30\n",
      "0.10429999977350235\n",
      "run: 31\n",
      "0.10369999706745148\n",
      "run: 32\n",
      "0.10360000282526016\n",
      "run: 33\n",
      "0.10270000249147415\n",
      "run: 34\n",
      "0.1031000018119812\n",
      "run: 35\n",
      "0.10320000350475311\n",
      "run: 36\n",
      "0.1046999990940094\n",
      "run: 37\n",
      "0.1039000004529953\n",
      "run: 38\n",
      "0.10379999876022339\n",
      "run: 39\n",
      "0.10450000315904617\n",
      "run: 40\n",
      "0.10199999809265137\n",
      "run: 41\n",
      "0.10239999741315842\n",
      "run: 42\n",
      "0.10480000078678131\n",
      "run: 43\n",
      "0.10189999639987946\n",
      "run: 44\n",
      "0.10189999639987946\n",
      "run: 45\n",
      "0.10440000146627426\n",
      "run: 46\n",
      "0.10490000247955322\n",
      "run: 47\n",
      "0.10459999740123749\n",
      "run: 48\n",
      "0.10450000315904617\n",
      "run: 49\n",
      "0.10260000079870224\n",
      "run: 50\n",
      "0.10300000011920929\n",
      "run: 51\n",
      "0.10499999672174454\n",
      "run: 52\n",
      "0.10209999978542328\n",
      "run: 53\n",
      "0.10239999741315842\n",
      "run: 54\n",
      "0.10980000346899033\n",
      "run: 55\n",
      "0.11060000211000443\n",
      "run: 56\n",
      "0.10899999737739563\n",
      "run: 57\n",
      "0.10530000180006027\n",
      "run: 58\n",
      "0.10419999808073044\n",
      "run: 59\n",
      "0.1039000004529953\n",
      "run: 60\n",
      "0.1039000004529953\n",
      "run: 61\n",
      "0.10419999808073044\n",
      "run: 62\n",
      "0.10419999808073044\n",
      "run: 63\n",
      "0.10490000247955322\n",
      "run: 64\n",
      "0.10450000315904617\n",
      "run: 65\n",
      "0.10400000214576721\n",
      "run: 66\n",
      "0.10499999672174454\n",
      "run: 67\n",
      "0.10270000249147415\n",
      "run: 68\n",
      "0.1031000018119812\n",
      "run: 69\n",
      "0.10679999738931656\n",
      "run: 70\n",
      "0.10249999910593033\n",
      "run: 71\n",
      "0.10260000079870224\n",
      "run: 72\n",
      "0.10480000078678131\n",
      "run: 73\n",
      "0.10509999841451645\n",
      "run: 74\n",
      "0.10480000078678131\n",
      "run: 75\n",
      "0.1054999977350235\n",
      "run: 76\n",
      "0.10339999943971634\n",
      "run: 77\n",
      "0.10350000113248825\n",
      "run: 78\n",
      "0.10660000145435333\n",
      "run: 79\n",
      "0.10300000011920929\n",
      "run: 80\n",
      "0.10320000350475311\n",
      "run: 81\n",
      "0.1298999935388565\n",
      "run: 82\n",
      "0.12479999661445618\n",
      "run: 83\n",
      "0.1242000013589859\n",
      "run: 84\n",
      "0.13410000503063202\n",
      "run: 85\n",
      "0.12520000338554382\n",
      "run: 86\n",
      "0.12430000305175781\n",
      "run: 87\n",
      "0.13040000200271606\n",
      "run: 88\n",
      "0.12639999389648438\n",
      "run: 89\n",
      "0.12559999525547028\n",
      "run: 90\n",
      "0.11060000211000443\n",
      "run: 91\n",
      "0.13269999623298645\n",
      "run: 92\n",
      "0.13500000536441803\n",
      "run: 93\n",
      "0.1298000067472458\n",
      "run: 94\n",
      "0.13300000131130219\n",
      "run: 95\n",
      "0.13169999420642853\n",
      "run: 96\n",
      "0.13369999825954437\n",
      "run: 97\n",
      "0.13210000097751617\n",
      "run: 98\n",
      "0.13109999895095825\n",
      "run: 99\n",
      "0.10649999976158142\n",
      "run: 100\n",
      "0.12700000405311584\n",
      "run: 101\n",
      "0.13249999284744263\n",
      "run: 102\n",
      "0.12610000371932983\n",
      "run: 103\n",
      "0.1324000060558319\n",
      "run: 104\n",
      "0.13179999589920044\n",
      "run: 105\n",
      "0.12999999523162842\n",
      "run: 106\n",
      "0.1324000060558319\n",
      "run: 107\n",
      "0.131400004029274\n",
      "run: 108\n",
      "0.13429999351501465\n",
      "run: 109\n",
      "0.13689999282360077\n",
      "run: 110\n",
      "0.13590000569820404\n",
      "run: 111\n",
      "0.1428000032901764\n",
      "run: 112\n",
      "0.13050000369548798\n",
      "run: 113\n",
      "0.12950000166893005\n",
      "run: 114\n",
      "0.1446000039577484\n",
      "run: 115\n",
      "0.13050000369548798\n",
      "run: 116\n",
      "0.1298999935388565\n",
      "run: 117\n",
      "0.10980000346899033\n",
      "run: 118\n",
      "0.12460000067949295\n",
      "run: 119\n",
      "0.1298999935388565\n",
      "run: 120\n",
      "0.13339999318122864\n",
      "run: 121\n",
      "0.14350000023841858\n",
      "run: 122\n",
      "0.14270000159740448\n",
      "run: 123\n",
      "0.13619999587535858\n",
      "run: 124\n",
      "0.1436000019311905\n",
      "run: 125\n",
      "0.14139999449253082\n",
      "run: 126\n",
      "0.10790000110864639\n",
      "run: 127\n",
      "0.1185000017285347\n",
      "run: 128\n",
      "0.12549999356269836\n",
      "run: 129\n",
      "0.13210000097751617\n",
      "run: 130\n",
      "0.1437000036239624\n",
      "run: 131\n",
      "0.1428000032901764\n",
      "run: 132\n",
      "0.13580000400543213\n",
      "run: 133\n",
      "0.14270000159740448\n",
      "run: 134\n",
      "0.1437000036239624\n",
      "run: 135\n",
      "0.12970000505447388\n",
      "run: 136\n",
      "0.13680000603199005\n",
      "run: 137\n",
      "0.1356000006198883\n",
      "run: 138\n",
      "0.13830000162124634\n",
      "run: 139\n",
      "0.13089999556541443\n",
      "run: 140\n",
      "0.13030000030994415\n",
      "run: 141\n",
      "0.13920000195503235\n",
      "run: 142\n",
      "0.13130000233650208\n",
      "run: 143\n",
      "0.13009999692440033\n",
      "run: 144\n",
      "0.11190000176429749\n",
      "run: 145\n",
      "0.12700000405311584\n",
      "run: 146\n",
      "0.13330000638961792\n",
      "run: 147\n",
      "0.13349999487400055\n",
      "run: 148\n",
      "0.14720000326633453\n",
      "run: 149\n",
      "0.14569999277591705\n",
      "run: 150\n",
      "0.13729999959468842\n",
      "run: 151\n",
      "0.1459999978542328\n",
      "run: 152\n",
      "0.14499999582767487\n",
      "run: 153\n",
      "0.11010000109672546\n",
      "run: 154\n",
      "0.12099999934434891\n",
      "run: 155\n",
      "0.12860000133514404\n",
      "run: 156\n",
      "0.13269999623298645\n",
      "run: 157\n",
      "0.14569999277591705\n",
      "run: 158\n",
      "0.14630000293254852\n",
      "run: 159\n",
      "0.13840000331401825\n",
      "run: 160\n",
      "0.1453000009059906\n",
      "run: 161\n",
      "0.1453000009059906\n",
      "run: 162\n",
      "0.1298000067472458\n",
      "run: 163\n",
      "0.12139999866485596\n",
      "run: 164\n",
      "0.12020000070333481\n",
      "run: 165\n",
      "0.131400004029274\n",
      "run: 166\n",
      "0.11890000104904175\n",
      "run: 167\n",
      "0.11860000342130661\n",
      "run: 168\n",
      "0.1331000030040741\n",
      "run: 169\n",
      "0.12020000070333481\n",
      "run: 170\n",
      "0.11909999698400497\n",
      "run: 171\n",
      "0.1200999990105629\n",
      "run: 172\n",
      "0.13699999451637268\n",
      "run: 173\n",
      "0.13580000400543213\n",
      "run: 174\n",
      "0.13539999723434448\n",
      "run: 175\n",
      "0.12999999523162842\n",
      "run: 176\n",
      "0.12890000641345978\n",
      "run: 177\n",
      "0.13590000569820404\n",
      "run: 178\n",
      "0.12960000336170197\n",
      "run: 179\n",
      "0.12849999964237213\n",
      "run: 180\n",
      "0.11599999666213989\n",
      "run: 181\n",
      "0.13269999623298645\n",
      "run: 182\n",
      "0.1347000002861023\n",
      "run: 183\n",
      "0.1324000060558319\n",
      "run: 184\n",
      "0.13179999589920044\n",
      "run: 185\n",
      "0.12960000336170197\n",
      "run: 186\n",
      "0.13539999723434448\n",
      "run: 187\n",
      "0.13040000200271606\n",
      "run: 188\n",
      "0.12809999287128448\n",
      "run: 189\n",
      "0.14069999754428864\n",
      "run: 190\n",
      "0.13220000267028809\n",
      "run: 191\n",
      "0.131400004029274\n",
      "run: 192\n",
      "0.13940000534057617\n",
      "run: 193\n",
      "0.125900000333786\n",
      "run: 194\n",
      "0.125\n",
      "run: 195\n",
      "0.1412999927997589\n",
      "run: 196\n",
      "0.12630000710487366\n",
      "run: 197\n",
      "0.12559999525547028\n",
      "run: 198\n",
      "0.120899997651577\n",
      "run: 199\n",
      "0.14229999482631683\n",
      "run: 200\n",
      "0.14550000429153442\n",
      "run: 201\n",
      "0.14000000059604645\n",
      "run: 202\n",
      "0.1477999985218048\n",
      "run: 203\n",
      "0.1477999985218048\n",
      "run: 204\n",
      "0.1459999978542328\n",
      "run: 205\n",
      "0.14800000190734863\n",
      "run: 206\n",
      "0.14569999277591705\n",
      "run: 207\n",
      "0.11760000139474869\n",
      "run: 208\n",
      "0.13770000636577606\n",
      "run: 209\n",
      "0.1437000036239624\n",
      "run: 210\n",
      "0.1388999968767166\n",
      "run: 211\n",
      "0.148499995470047\n",
      "run: 212\n",
      "0.14800000190734863\n",
      "run: 213\n",
      "0.1428000032901764\n",
      "run: 214\n",
      "0.14730000495910645\n",
      "run: 215\n",
      "0.14710000157356262\n",
      "run: 216\n",
      "0.14000000059604645\n",
      "run: 217\n",
      "0.13410000503063202\n",
      "run: 218\n",
      "0.13379999995231628\n",
      "run: 219\n",
      "0.1420000046491623\n",
      "run: 220\n",
      "0.1282999962568283\n",
      "run: 221\n",
      "0.12790000438690186\n",
      "run: 222\n",
      "0.14300000667572021\n",
      "run: 223\n",
      "0.12860000133514404\n",
      "run: 224\n",
      "0.12770000100135803\n",
      "run: 225\n",
      "0.1242000013589859\n",
      "run: 226\n",
      "0.1446000039577484\n",
      "run: 227\n",
      "0.1468999981880188\n",
      "run: 228\n",
      "0.13809999823570251\n",
      "run: 229\n",
      "0.15209999680519104\n",
      "run: 230\n",
      "0.15029999613761902\n",
      "run: 231\n",
      "0.14169999957084656\n",
      "run: 232\n",
      "0.15039999783039093\n",
      "run: 233\n",
      "0.1492999941110611\n",
      "run: 234\n",
      "0.12060000002384186\n",
      "run: 235\n",
      "0.13989999890327454\n",
      "run: 236\n",
      "0.1467999964952469\n",
      "run: 237\n",
      "0.1370999962091446\n",
      "run: 238\n",
      "0.15289999544620514\n",
      "run: 239\n",
      "0.15119999647140503\n",
      "run: 240\n",
      "0.14100000262260437\n",
      "run: 241\n",
      "0.15240000188350677\n",
      "run: 242\n",
      "0.14970000088214874\n",
      "run: 243\n",
      "0.18219999969005585\n",
      "run: 244\n",
      "0.15790000557899475\n",
      "run: 245\n",
      "0.15870000422000885\n",
      "run: 246\n",
      "0.15459999442100525\n",
      "run: 247\n",
      "0.14730000495910645\n",
      "run: 248\n",
      "0.14659999310970306\n",
      "run: 249\n",
      "0.15639999508857727\n",
      "run: 250\n",
      "0.14730000495910645\n",
      "run: 251\n",
      "0.14589999616146088\n",
      "run: 252\n",
      "0.2287999987602234\n",
      "run: 253\n",
      "0.20659999549388885\n",
      "run: 254\n",
      "0.20970000326633453\n",
      "run: 255\n",
      "0.2214999943971634\n",
      "run: 256\n",
      "0.20309999585151672\n",
      "run: 257\n",
      "0.20200000703334808\n",
      "run: 258\n",
      "0.21799999475479126\n",
      "run: 259\n",
      "0.19760000705718994\n",
      "run: 260\n",
      "0.19589999318122864\n",
      "run: 261\n",
      "0.23170000314712524\n",
      "run: 262\n",
      "0.2078000009059906\n",
      "run: 263\n",
      "0.2159000039100647\n",
      "run: 264\n",
      "0.23309999704360962\n",
      "run: 265\n",
      "0.2150000035762787\n",
      "run: 266\n",
      "0.21449999511241913\n",
      "run: 267\n",
      "0.23019999265670776\n",
      "run: 268\n",
      "0.20880000293254852\n",
      "run: 269\n",
      "0.20669999718666077\n",
      "run: 270\n",
      "0.2689000070095062\n",
      "run: 271\n",
      "0.2410999983549118\n",
      "run: 272\n",
      "0.23440000414848328\n",
      "run: 273\n",
      "0.21950000524520874\n",
      "run: 274\n",
      "0.218299999833107\n",
      "run: 275\n",
      "0.21950000524520874\n",
      "run: 276\n",
      "0.21400000154972076\n",
      "run: 277\n",
      "0.21359999477863312\n",
      "run: 278\n",
      "0.21220000088214874\n",
      "run: 279\n",
      "0.2578999996185303\n",
      "run: 280\n",
      "0.2858999967575073\n",
      "run: 281\n",
      "0.290800005197525\n",
      "run: 282\n",
      "0.2976999878883362\n",
      "run: 283\n",
      "0.3084000051021576\n",
      "run: 284\n",
      "0.3111000061035156\n",
      "run: 285\n",
      "0.30079999566078186\n",
      "run: 286\n",
      "0.30379998683929443\n",
      "run: 287\n",
      "0.30630001425743103\n",
      "run: 288\n",
      "0.2531999945640564\n",
      "run: 289\n",
      "0.2856000065803528\n",
      "run: 290\n",
      "0.29249998927116394\n",
      "run: 291\n",
      "0.3005000054836273\n",
      "run: 292\n",
      "0.31290000677108765\n",
      "run: 293\n",
      "0.3172999918460846\n",
      "run: 294\n",
      "0.3057999908924103\n",
      "run: 295\n",
      "0.3138999938964844\n",
      "run: 296\n",
      "0.3158999979496002\n",
      "run: 297\n",
      "0.2734000086784363\n",
      "run: 298\n",
      "0.25850000977516174\n",
      "run: 299\n",
      "0.25220000743865967\n",
      "run: 300\n",
      "0.23180000483989716\n",
      "run: 301\n",
      "0.2363000065088272\n",
      "run: 302\n",
      "0.2378000020980835\n",
      "run: 303\n",
      "0.23090000450611115\n",
      "run: 304\n",
      "0.2296999990940094\n",
      "run: 305\n",
      "0.22779999673366547\n",
      "run: 306\n",
      "0.25679999589920044\n",
      "run: 307\n",
      "0.2985000014305115\n",
      "run: 308\n",
      "0.30309998989105225\n",
      "run: 309\n",
      "0.3125\n",
      "run: 310\n",
      "0.3253999948501587\n",
      "run: 311\n",
      "0.3303000032901764\n",
      "run: 312\n",
      "0.32120001316070557\n",
      "run: 313\n",
      "0.32690000534057617\n",
      "run: 314\n",
      "0.3287999927997589\n",
      "run: 315\n",
      "0.250900000333786\n",
      "run: 316\n",
      "0.2944999933242798\n",
      "run: 317\n",
      "0.30160000920295715\n",
      "run: 318\n",
      "0.3151000142097473\n",
      "run: 319\n",
      "0.3312999904155731\n",
      "run: 320\n",
      "0.33730000257492065\n",
      "run: 321\n",
      "0.3244999945163727\n",
      "run: 322\n",
      "0.33489999175071716\n",
      "run: 323\n",
      "0.3400000035762787\n",
      "run: 324\n",
      "0.2549999952316284\n",
      "run: 325\n",
      "0.2232999950647354\n",
      "run: 326\n",
      "0.22699999809265137\n",
      "run: 327\n",
      "0.25870001316070557\n",
      "run: 328\n",
      "0.25609999895095825\n",
      "run: 329\n",
      "0.25529998540878296\n",
      "run: 330\n",
      "0.2621999979019165\n",
      "run: 331\n",
      "0.2587999999523163\n",
      "run: 332\n",
      "0.25450000166893005\n",
      "run: 333\n",
      "0.3409000039100647\n",
      "run: 334\n",
      "0.35100001096725464\n",
      "run: 335\n",
      "0.35269999504089355\n",
      "run: 336\n",
      "0.3887999951839447\n",
      "run: 337\n",
      "0.4027000069618225\n",
      "run: 338\n",
      "0.40070000290870667\n",
      "run: 339\n",
      "0.3894999921321869\n",
      "run: 340\n",
      "0.3977999985218048\n",
      "run: 341\n",
      "0.39480000734329224\n",
      "run: 342\n",
      "0.3463999927043915\n",
      "run: 343\n",
      "0.3652999997138977\n",
      "run: 344\n",
      "0.3684999942779541\n",
      "run: 345\n",
      "0.4041999876499176\n",
      "run: 346\n",
      "0.42640000581741333\n",
      "run: 347\n",
      "0.42419999837875366\n",
      "run: 348\n",
      "0.4034999907016754\n",
      "run: 349\n",
      "0.42320001125335693\n",
      "run: 350\n",
      "0.41760000586509705\n",
      "run: 351\n",
      "0.3637000024318695\n",
      "run: 352\n",
      "0.3619000017642975\n",
      "run: 353\n",
      "0.3668999969959259\n",
      "run: 354\n",
      "0.4138000011444092\n",
      "run: 355\n",
      "0.44600000977516174\n",
      "run: 356\n",
      "0.4453999996185303\n",
      "run: 357\n",
      "0.41819998621940613\n",
      "run: 358\n",
      "0.4496999979019165\n",
      "run: 359\n",
      "0.44679999351501465\n",
      "run: 360\n",
      "0.4212000072002411\n",
      "run: 361\n",
      "0.47760000824928284\n",
      "run: 362\n",
      "0.4878000020980835\n",
      "run: 363\n",
      "0.515999972820282\n",
      "run: 364\n",
      "0.570900022983551\n",
      "run: 365\n",
      "0.5698000192642212\n",
      "run: 366\n",
      "0.5160999894142151\n",
      "run: 367\n",
      "0.5685999989509583\n",
      "run: 368\n",
      "0.5672000050544739\n",
      "run: 369\n",
      "0.4260999858379364\n",
      "run: 370\n",
      "0.4869000017642975\n",
      "run: 371\n",
      "0.49630001187324524\n",
      "run: 372\n",
      "0.5198000073432922\n",
      "run: 373\n",
      "0.5845999717712402\n",
      "run: 374\n",
      "0.583899974822998\n",
      "run: 375\n",
      "0.5220000147819519\n",
      "run: 376\n",
      "0.5781999826431274\n",
      "run: 377\n",
      "0.5817999839782715\n",
      "run: 378\n",
      "0.37049999833106995\n",
      "run: 379\n",
      "0.38119998574256897\n",
      "run: 380\n",
      "0.3849000036716461\n",
      "run: 381\n",
      "0.42590001225471497\n",
      "run: 382\n",
      "0.46939998865127563\n",
      "run: 383\n",
      "0.4677000045776367\n",
      "run: 384\n",
      "0.4343999922275543\n",
      "run: 385\n",
      "0.476500004529953\n",
      "run: 386\n",
      "0.4733999967575073\n",
      "run: 387\n",
      "0.4242999851703644\n",
      "run: 388\n",
      "0.49070000648498535\n",
      "run: 389\n",
      "0.5001999735832214\n",
      "run: 390\n",
      "0.5185999870300293\n",
      "run: 391\n",
      "0.5827000141143799\n",
      "run: 392\n",
      "0.5820000171661377\n",
      "run: 393\n",
      "0.5189999938011169\n",
      "run: 394\n",
      "0.5834000110626221\n",
      "run: 395\n",
      "0.583899974822998\n",
      "run: 396\n",
      "0.42579999566078186\n",
      "run: 397\n",
      "0.4943000078201294\n",
      "run: 398\n",
      "0.5056999921798706\n",
      "run: 399\n",
      "0.5221999883651733\n",
      "run: 400\n",
      "0.5956000089645386\n",
      "run: 401\n",
      "0.5921000242233276\n",
      "run: 402\n",
      "0.5230000019073486\n",
      "run: 403\n",
      "0.59170001745224\n",
      "run: 404\n",
      "0.5929999947547913\n",
      "run: 405\n",
      "0.2800999879837036\n",
      "run: 406\n",
      "0.24819999933242798\n",
      "run: 407\n",
      "0.2517000138759613\n",
      "run: 408\n",
      "0.3125999867916107\n",
      "run: 409\n",
      "0.3077000081539154\n",
      "run: 410\n",
      "0.3068000078201294\n",
      "run: 411\n",
      "0.31700000166893005\n",
      "run: 412\n",
      "0.3163999915122986\n",
      "run: 413\n",
      "0.3116999864578247\n",
      "run: 414\n",
      "0.37229999899864197\n",
      "run: 415\n",
      "0.3849000036716461\n",
      "run: 416\n",
      "0.3898000121116638\n",
      "run: 417\n",
      "0.44769999384880066\n",
      "run: 418\n",
      "0.47049999237060547\n",
      "run: 419\n",
      "0.4672999978065491\n",
      "run: 420\n",
      "0.45239999890327454\n",
      "run: 421\n",
      "0.4729999899864197\n",
      "run: 422\n",
      "0.47029998898506165\n",
      "run: 423\n",
      "0.3756999969482422\n",
      "run: 424\n",
      "0.3991999924182892\n",
      "run: 425\n",
      "0.40389999747276306\n",
      "run: 426\n",
      "0.46070000529289246\n",
      "run: 427\n",
      "0.4945000112056732\n",
      "run: 428\n",
      "0.4887999892234802\n",
      "run: 429\n",
      "0.46459999680519104\n",
      "run: 430\n",
      "0.49390000104904175\n",
      "run: 431\n",
      "0.4909999966621399\n",
      "run: 432\n",
      "0.38019999861717224\n",
      "run: 433\n",
      "0.38440001010894775\n",
      "run: 434\n",
      "0.3889999985694885\n",
      "run: 435\n",
      "0.46939998865127563\n",
      "run: 436\n",
      "0.5031999945640564\n",
      "run: 437\n",
      "0.5011000037193298\n",
      "run: 438\n",
      "0.47870001196861267\n",
      "run: 439\n",
      "0.5152999758720398\n",
      "run: 440\n",
      "0.5083000063896179\n",
      "run: 441\n",
      "0.45100000500679016\n",
      "run: 442\n",
      "0.5101000070571899\n",
      "run: 443\n",
      "0.5164999961853027\n",
      "run: 444\n",
      "0.5580999851226807\n",
      "run: 445\n",
      "0.6276000142097473\n",
      "run: 446\n",
      "0.6258999705314636\n",
      "run: 447\n",
      "0.5605000257492065\n",
      "run: 448\n",
      "0.6248999834060669\n",
      "run: 449\n",
      "0.6251000165939331\n",
      "run: 450\n",
      "0.45170000195503235\n",
      "run: 451\n",
      "0.521399974822998\n",
      "run: 452\n",
      "0.5264999866485596\n",
      "run: 453\n",
      "0.5648000240325928\n",
      "run: 454\n",
      "0.6366999745368958\n",
      "run: 455\n",
      "0.633400022983551\n",
      "run: 456\n",
      "0.566100001335144\n",
      "run: 457\n",
      "0.6344000101089478\n",
      "run: 458\n",
      "0.6367999911308289\n",
      "run: 459\n",
      "0.38580000400543213\n",
      "run: 460\n",
      "0.4058000147342682\n",
      "run: 461\n",
      "0.4092000126838684\n",
      "run: 462\n",
      "0.4828999936580658\n",
      "run: 463\n",
      "0.5268999934196472\n",
      "run: 464\n",
      "0.5250999927520752\n",
      "run: 465\n",
      "0.4916999936103821\n",
      "run: 466\n",
      "0.5353000164031982\n",
      "run: 467\n",
      "0.5333999991416931\n",
      "run: 468\n",
      "0.4521999955177307\n",
      "run: 469\n",
      "0.5202999711036682\n",
      "run: 470\n",
      "0.5281999707221985\n",
      "run: 471\n",
      "0.560699999332428\n",
      "run: 472\n",
      "0.633899986743927\n",
      "run: 473\n",
      "0.6316999793052673\n",
      "run: 474\n",
      "0.5619999766349792\n",
      "run: 475\n",
      "0.6344000101089478\n",
      "run: 476\n",
      "0.6351000070571899\n",
      "run: 477\n",
      "0.45339998602867126\n",
      "run: 478\n",
      "0.5264999866485596\n",
      "run: 479\n",
      "0.5343999862670898\n",
      "run: 480\n",
      "0.567799985408783\n",
      "run: 481\n",
      "0.6406999826431274\n",
      "run: 482\n",
      "0.6389999985694885\n",
      "run: 483\n",
      "0.5662999749183655\n",
      "run: 484\n",
      "0.6413999795913696\n",
      "run: 485\n",
      "0.6431000232696533\n",
      "run: 486\n",
      "0.23569999635219574\n",
      "run: 487\n",
      "0.1873999983072281\n",
      "run: 488\n",
      "0.193900004029274\n",
      "run: 489\n",
      "0.1996999979019165\n",
      "run: 490\n",
      "0.19679999351501465\n",
      "run: 491\n",
      "0.19760000705718994\n",
      "run: 492\n",
      "0.1964000016450882\n",
      "run: 493\n",
      "0.1956000030040741\n",
      "run: 494\n",
      "0.1932000070810318\n",
      "run: 495\n",
      "0.31709998846054077\n",
      "run: 496\n",
      "0.3167000114917755\n",
      "run: 497\n",
      "0.31630000472068787\n",
      "run: 498\n",
      "0.3334999978542328\n",
      "run: 499\n",
      "0.3301999866962433\n",
      "run: 500\n",
      "0.3301999866962433\n",
      "run: 501\n",
      "0.33219999074935913\n",
      "run: 502\n",
      "0.3197999894618988\n",
      "run: 503\n",
      "0.319599986076355\n",
      "run: 504\n",
      "0.3172000050544739\n",
      "run: 505\n",
      "0.3280999958515167\n",
      "run: 506\n",
      "0.328900009393692\n",
      "run: 507\n",
      "0.3490000069141388\n",
      "run: 508\n",
      "0.3499000072479248\n",
      "run: 509\n",
      "0.3517000079154968\n",
      "run: 510\n",
      "0.3474000096321106\n",
      "run: 511\n",
      "0.34130001068115234\n",
      "run: 512\n",
      "0.34119999408721924\n",
      "run: 513\n",
      "0.3314000070095062\n",
      "run: 514\n",
      "0.3228999972343445\n",
      "run: 515\n",
      "0.320499986410141\n",
      "run: 516\n",
      "0.311599999666214\n",
      "run: 517\n",
      "0.3292999863624573\n",
      "run: 518\n",
      "0.33090001344680786\n",
      "run: 519\n",
      "0.31769999861717224\n",
      "run: 520\n",
      "0.32109999656677246\n",
      "run: 521\n",
      "0.320499986410141\n",
      "run: 522\n",
      "0.3222000002861023\n",
      "run: 523\n",
      "0.3799000084400177\n",
      "run: 524\n",
      "0.38749998807907104\n",
      "run: 525\n",
      "0.4011000096797943\n",
      "run: 526\n",
      "0.44350001215934753\n",
      "run: 527\n",
      "0.447299987077713\n",
      "run: 528\n",
      "0.4133000075817108\n",
      "run: 529\n",
      "0.4474000036716461\n",
      "run: 530\n",
      "0.44699999690055847\n",
      "run: 531\n",
      "0.313400000333786\n",
      "run: 532\n",
      "0.3767000138759613\n",
      "run: 533\n",
      "0.3840000033378601\n",
      "run: 534\n",
      "0.4018000066280365\n",
      "run: 535\n",
      "0.4514000117778778\n",
      "run: 536\n",
      "0.4560999870300293\n",
      "run: 537\n",
      "0.41609999537467957\n",
      "run: 538\n",
      "0.4528000056743622\n",
      "run: 539\n",
      "0.4571000039577484\n",
      "run: 540\n",
      "0.33550000190734863\n",
      "run: 541\n",
      "0.34380000829696655\n",
      "run: 542\n",
      "0.3431999981403351\n",
      "run: 543\n",
      "0.3269999921321869\n",
      "run: 544\n",
      "0.3573000133037567\n",
      "run: 545\n",
      "0.3578000068664551\n",
      "run: 546\n",
      "0.3393999934196472\n",
      "run: 547\n",
      "0.35030001401901245\n",
      "run: 548\n",
      "0.34940001368522644\n",
      "run: 549\n",
      "0.3172000050544739\n",
      "run: 550\n",
      "0.3865000009536743\n",
      "run: 551\n",
      "0.3944999873638153\n",
      "run: 552\n",
      "0.4180000126361847\n",
      "run: 553\n",
      "0.4634000062942505\n",
      "run: 554\n",
      "0.4690999984741211\n",
      "run: 555\n",
      "0.42989999055862427\n",
      "run: 556\n",
      "0.4652999937534332\n",
      "run: 557\n",
      "0.4677000045776367\n",
      "run: 558\n",
      "0.311599999666214\n",
      "run: 559\n",
      "0.38119998574256897\n",
      "run: 560\n",
      "0.39089998602867126\n",
      "run: 561\n",
      "0.415800005197525\n",
      "run: 562\n",
      "0.46709999442100525\n",
      "run: 563\n",
      "0.4724999964237213\n",
      "run: 564\n",
      "0.43209999799728394\n",
      "run: 565\n",
      "0.4702000021934509\n",
      "run: 566\n",
      "0.4756999909877777\n",
      "run: 567\n",
      "0.33799999952316284\n",
      "run: 568\n",
      "0.29589998722076416\n",
      "run: 569\n",
      "0.3018999993801117\n",
      "run: 570\n",
      "0.3693999946117401\n",
      "run: 571\n",
      "0.3817000091075897\n",
      "run: 572\n",
      "0.3797000050544739\n",
      "run: 573\n",
      "0.3779999911785126\n",
      "run: 574\n",
      "0.3937000036239624\n",
      "run: 575\n",
      "0.39070001244544983\n",
      "run: 576\n",
      "0.42669999599456787\n",
      "run: 577\n",
      "0.4602000117301941\n",
      "run: 578\n",
      "0.46560001373291016\n",
      "run: 579\n",
      "0.5282999873161316\n",
      "run: 580\n",
      "0.5730000138282776\n",
      "run: 581\n",
      "0.5742999911308289\n",
      "run: 582\n",
      "0.5376999974250793\n",
      "run: 583\n",
      "0.5751000046730042\n",
      "run: 584\n",
      "0.5752000212669373\n",
      "run: 585\n",
      "0.43130001425743103\n",
      "run: 586\n",
      "0.4717999994754791\n",
      "run: 587\n",
      "0.4767000079154968\n",
      "run: 588\n",
      "0.5400000214576721\n",
      "run: 589\n",
      "0.5950999855995178\n",
      "run: 590\n",
      "0.5952000021934509\n",
      "run: 591\n",
      "0.546999990940094\n",
      "run: 592\n",
      "0.5946000218391418\n",
      "run: 593\n",
      "0.598800003528595\n",
      "run: 594\n",
      "0.4350000023841858\n",
      "run: 595\n",
      "0.4672999978065491\n",
      "run: 596\n",
      "0.4706999957561493\n",
      "run: 597\n",
      "0.5407999753952026\n",
      "run: 598\n",
      "0.5924000144004822\n",
      "run: 599\n",
      "0.5921000242233276\n",
      "run: 600\n",
      "0.551800012588501\n",
      "run: 601\n",
      "0.5972999930381775\n",
      "run: 602\n",
      "0.5968000292778015\n",
      "run: 603\n",
      "0.4968999922275543\n",
      "run: 604\n",
      "0.572700023651123\n",
      "run: 605\n",
      "0.5752999782562256\n",
      "run: 606\n",
      "0.6302000284194946\n",
      "run: 607\n",
      "0.7091000080108643\n",
      "run: 608\n",
      "0.7059999704360962\n",
      "run: 609\n",
      "0.6349999904632568\n",
      "run: 610\n",
      "0.7135000228881836\n",
      "run: 611\n",
      "0.7113999724388123\n",
      "run: 612\n",
      "0.4945000112056732\n",
      "run: 613\n",
      "0.5781999826431274\n",
      "run: 614\n",
      "0.5824999809265137\n",
      "run: 615\n",
      "0.6340000033378601\n",
      "run: 616\n",
      "0.7110000252723694\n",
      "run: 617\n",
      "0.7106000185012817\n",
      "run: 618\n",
      "0.6401000022888184\n",
      "run: 619\n",
      "0.7163000106811523\n",
      "run: 620\n",
      "0.7192999720573425\n",
      "run: 621\n",
      "0.4406000077724457\n",
      "run: 622\n",
      "0.4796999990940094\n",
      "run: 623\n",
      "0.4832000136375427\n",
      "run: 624\n",
      "0.5490000247955322\n",
      "run: 625\n",
      "0.6118000149726868\n",
      "run: 626\n",
      "0.6087999939918518\n",
      "run: 627\n",
      "0.5598999857902527\n",
      "run: 628\n",
      "0.6186000108718872\n",
      "run: 629\n",
      "0.6166999936103821\n",
      "run: 630\n",
      "0.49900001287460327\n",
      "run: 631\n",
      "0.5771999955177307\n",
      "run: 632\n",
      "0.5824999809265137\n",
      "run: 633\n",
      "0.6352999806404114\n",
      "run: 634\n",
      "0.7117000222206116\n",
      "run: 635\n",
      "0.7084000110626221\n",
      "run: 636\n",
      "0.636900007724762\n",
      "run: 637\n",
      "0.7159000039100647\n",
      "run: 638\n",
      "0.7149999737739563\n",
      "run: 639\n",
      "0.4961000084877014\n",
      "run: 640\n",
      "0.5813000202178955\n",
      "run: 641\n",
      "0.5860999822616577\n",
      "run: 642\n",
      "0.6385999917984009\n",
      "run: 643\n",
      "0.7145000100135803\n",
      "run: 644\n",
      "0.7135999798774719\n",
      "run: 645\n",
      "0.641700029373169\n",
      "run: 646\n",
      "0.7206000089645386\n",
      "run: 647\n",
      "0.7199000120162964\n",
      "run: 648\n",
      "0.35510000586509705\n",
      "run: 649\n",
      "0.3303000032901764\n",
      "run: 650\n",
      "0.3327000141143799\n",
      "run: 651\n",
      "0.4056999981403351\n",
      "run: 652\n",
      "0.42989999055862427\n",
      "run: 653\n",
      "0.4271000027656555\n",
      "run: 654\n",
      "0.4187999963760376\n",
      "run: 655\n",
      "0.4471000134944916\n",
      "run: 656\n",
      "0.4424000084400177\n",
      "run: 657\n",
      "0.43230000138282776\n",
      "run: 658\n",
      "0.47360000014305115\n",
      "run: 659\n",
      "0.47690001130104065\n",
      "run: 660\n",
      "0.546999990940094\n",
      "run: 661\n",
      "0.6015999913215637\n",
      "run: 662\n",
      "0.6008999943733215\n",
      "run: 663\n",
      "0.551800012588501\n",
      "run: 664\n",
      "0.6049000024795532\n",
      "run: 665\n",
      "0.6086000204086304\n",
      "run: 666\n",
      "0.43790000677108765\n",
      "run: 667\n",
      "0.4860000014305115\n",
      "run: 668\n",
      "0.48980000615119934\n",
      "run: 669\n",
      "0.557699978351593\n",
      "run: 670\n",
      "0.6169999837875366\n",
      "run: 671\n",
      "0.6176000237464905\n",
      "run: 672\n",
      "0.5633000135421753\n",
      "run: 673\n",
      "0.6182000041007996\n",
      "run: 674\n",
      "0.6220999956130981\n",
      "run: 675\n",
      "0.4431000053882599\n",
      "run: 676\n",
      "0.48190000653266907\n",
      "run: 677\n",
      "0.484499990940094\n",
      "run: 678\n",
      "0.5667999982833862\n",
      "run: 679\n",
      "0.6202999949455261\n",
      "run: 680\n",
      "0.6158000230789185\n",
      "run: 681\n",
      "0.5784000158309937\n",
      "run: 682\n",
      "0.6280999779701233\n",
      "run: 683\n",
      "0.6261000037193298\n",
      "run: 684\n",
      "0.5113000273704529\n",
      "run: 685\n",
      "0.5866000056266785\n",
      "run: 686\n",
      "0.5856999754905701\n",
      "run: 687\n",
      "0.6445000171661377\n",
      "run: 688\n",
      "0.7217000126838684\n",
      "run: 689\n",
      "0.7208999991416931\n",
      "run: 690\n",
      "0.6499000191688538\n",
      "run: 691\n",
      "0.7272999882698059\n",
      "run: 692\n",
      "0.7296000123023987\n",
      "run: 693\n",
      "0.5113999843597412\n",
      "run: 694\n",
      "0.5942999720573425\n",
      "run: 695\n",
      "0.5940999984741211\n",
      "run: 696\n",
      "0.645799994468689\n",
      "run: 697\n",
      "0.7264000177383423\n",
      "run: 698\n",
      "0.7242000102996826\n",
      "run: 699\n",
      "0.6486999988555908\n",
      "run: 700\n",
      "0.7294999957084656\n",
      "run: 701\n",
      "0.7347000241279602\n",
      "run: 702\n",
      "0.4487999975681305\n",
      "run: 703\n",
      "0.4934999942779541\n",
      "run: 704\n",
      "0.4957999885082245\n",
      "run: 705\n",
      "0.5777000188827515\n",
      "run: 706\n",
      "0.6352999806404114\n",
      "run: 707\n",
      "0.6319000124931335\n",
      "run: 708\n",
      "0.5885000228881836\n",
      "run: 709\n",
      "0.6434999704360962\n",
      "run: 710\n",
      "0.6406999826431274\n",
      "run: 711\n",
      "0.5131999850273132\n",
      "run: 712\n",
      "0.5891000032424927\n",
      "run: 713\n",
      "0.590399980545044\n",
      "run: 714\n",
      "0.6473000049591064\n",
      "run: 715\n",
      "0.7233999967575073\n",
      "run: 716\n",
      "0.7253000140190125\n",
      "run: 717\n",
      "0.6535999774932861\n",
      "run: 718\n",
      "0.7315000295639038\n",
      "run: 719\n",
      "0.73089998960495\n",
      "run: 720\n",
      "0.5127999782562256\n",
      "run: 721\n",
      "0.5946000218391418\n",
      "run: 722\n",
      "0.5964999794960022\n",
      "run: 723\n",
      "0.6499999761581421\n",
      "run: 724\n",
      "0.7267000079154968\n",
      "run: 725\n",
      "0.7247999906539917\n",
      "run: 726\n",
      "0.6542999744415283\n",
      "run: 727\n",
      "0.7322999835014343\n",
      "run: 728\n",
      "0.7353000044822693\n",
      "729 729\n",
      "new accuracy\n",
      "0.6431000232696533\n",
      "mean used Bits\n",
      "7.333333333333333\n"
     ]
    }
   ],
   "source": [
    "###second Version\n",
    "\n",
    "#determine needed non-fractional Bits\n",
    "modelCpy = copy.deepcopy(model)\n",
    "layerCount = len(model.layers)\n",
    "fractBitsSearchSpace = [2,4,8]\n",
    "tolerance = 0.1\n",
    "decimalBits = []\n",
    "nonEmptyLayerIdx = []\n",
    "accuracies = []\n",
    "for idx in range(layerCount):\n",
    "    if (modelCpy.layers[idx].get_weights() != []):\n",
    "        nonEmptyLayerIdx.append(idx)\n",
    "\n",
    "print(nonEmptyLayerIdx)\n",
    "\n",
    "\n",
    "for layerIdx in range(layerCount):\n",
    "    if not(layerIdx in nonEmptyLayerIdx):\n",
    "        decimalBits.append(0)\n",
    "    else:\n",
    "        minimum = math.floor(min(np.min(modelCpy.layers[layerIdx].get_weights()[0]), np.min(modelCpy.layers[layerIdx].get_weights()[1])))  \n",
    "        maximum = math.ceil(max(np.max(modelCpy.layers[layerIdx].get_weights()[0]), np.max(modelCpy.layers[layerIdx].get_weights()[1])))\n",
    "        valueRange = max(maximum, 0) - min(minimum, 0)\n",
    "        if (valueRange > 0):\n",
    "            decimalBits.append(math.ceil(math.log(valueRange, 2)))\n",
    "        else:\n",
    "            print(\"Error: Value Range is 0 or negative\")\n",
    "\n",
    "print (decimalBits)\n",
    "\n",
    "permutations = list(iter.product(fractBitsSearchSpace, repeat = len(nonEmptyLayerIdx)))\n",
    "print(len(permutations))\n",
    "print(permutations)\n",
    "for permutation in range(len(permutations)):\n",
    "    for layerIdx in nonEmptyLayerIdx:\n",
    "        currentFractBits = permutations[permutation][nonEmptyLayerIdx.index(layerIdx)]\n",
    "        newLayer = []\n",
    "        newLayer.append(fixedPointConversion(copy.deepcopy(model.layers[layerIdx].get_weights()[0]), decimalBits[layerIdx] + currentFractBits, currentFractBits))\n",
    "        newLayer.append(fixedPointConversion(copy.deepcopy(model.layers[layerIdx].get_weights()[1]), decimalBits[layerIdx] + currentFractBits, currentFractBits))\n",
    "        modelCpy.layers[layerIdx].set_weights(newLayer)\n",
    "    test_loss, test_acc = modelCpy.evaluate(testImages,  testLabels, verbose=0)\n",
    "    accuracies.append(test_acc)\n",
    "    print(\"run: \" + str(permutation))\n",
    "    print(test_acc)\n",
    "\n",
    "print(len(accuracies), len(permutations))\n",
    "\n",
    "ratios = []\n",
    "minimumAccuracy = max(accuracies) - tolerance\n",
    "for idx in range(len(permutations)):\n",
    "    if (accuracies[idx] < minimumAccuracy):\n",
    "        ratios.append(0)\n",
    "    else:\n",
    "        ratios.append(sum(permutations[idx]) / accuracies[idx])\n",
    "\n",
    "bestPermutation = permutations[ratios.index(max(ratios))]\n",
    "for layerIdx in nonEmptyLayerIdx:\n",
    "        currentFractBits = bestPermutation[nonEmptyLayerIdx.index(layerIdx)]\n",
    "        newLayer = []\n",
    "        newLayer.append(fixedPointConversion(copy.deepcopy(model.layers[layerIdx].get_weights()[0]), decimalBits[layerIdx] + currentFractBits, currentFractBits))\n",
    "        newLayer.append(fixedPointConversion(copy.deepcopy(model.layers[layerIdx].get_weights()[1]), decimalBits[layerIdx] + currentFractBits, currentFractBits))\n",
    "        modelCpy.layers[layerIdx].set_weights(newLayer)\n",
    "\n",
    "test_loss, test_acc = modelCpy.evaluate(testImages,  testLabels, verbose=0)\n",
    "print(\"new accuracy\")\n",
    "print(test_acc)\n",
    "print(\"mean used Bits\")\n",
    "print(sum(bestPermutation)/len(bestPermutation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'FuncGraph' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\7Zylo\\source\\VSC workplaces\\Image classifier\\ImageClassifier.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/7Zylo/source/VSC%20workplaces/Image%20classifier/ImageClassifier.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#optimizes layer by layer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/7Zylo/source/VSC%20workplaces/Image%20classifier/ImageClassifier.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m currentLayer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(layerCount):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/7Zylo/source/VSC%20workplaces/Image%20classifier/ImageClassifier.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     originalLayer \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39;49mdeepcopy(model\u001b[39m.\u001b[39;49mlayers[currentLayer])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/7Zylo/source/VSC%20workplaces/Image%20classifier/ImageClassifier.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m#only computes if layer has weights\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/7Zylo/source/VSC%20workplaces/Image%20classifier/ImageClassifier.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mif\u001b[39;00m (originalLayer\u001b[39m.\u001b[39mget_weights() \u001b[39m!=\u001b[39m []):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/7Zylo/source/VSC%20workplaces/Image%20classifier/ImageClassifier.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m#initializes matrix for storing layer accuracy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "    \u001b[1;31m[... skipping similar frames: deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "    \u001b[1;31m[... skipping similar frames: deepcopy at line 146 (2 times), _deepcopy_dict at line 231 (1 times), _reconstruct at line 271 (1 times), deepcopy at line 172 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "    \u001b[1;31m[... skipping similar frames: deepcopy at line 146 (31 times), _deepcopy_dict at line 231 (21 times), _reconstruct at line 271 (21 times), deepcopy at line 172 (21 times), _deepcopy_list at line 206 (9 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "    \u001b[1;31m[... skipping similar frames: deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[39m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[39m=\u001b[39m [deepcopy(a, memo) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[39m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[39m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[39m=\u001b[39m [deepcopy(a, memo) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[39m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "    \u001b[1;31m[... skipping similar frames: deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\7Zylo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:161\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    159\u001b[0m reductor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__reduce_ex__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[39mif\u001b[39;00m reductor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     rv \u001b[39m=\u001b[39m reductor(\u001b[39m4\u001b[39m)\n\u001b[0;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     reductor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__reduce__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'FuncGraph' object"
     ]
    }
   ],
   "source": [
    "###first Version\n",
    "fractBitsList = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22]\n",
    "maxBitSize = 24\n",
    "tolerancePerLayer = 0.05\n",
    "layerCount = len(model.layers)\n",
    "averageStorageUse = []\n",
    "accuracyDeveloptment = [test_acc]\n",
    "\n",
    "#optimizes layer by layer\n",
    "for currentLayer in range(layerCount):\n",
    "    originalLayer = copy.deepcopy(model.layers[currentLayer])\n",
    "    #only computes if layer has weights\n",
    "    if (originalLayer.get_weights() != []):\n",
    "        #initializes matrix for storing layer accuracy\n",
    "        layerAccuracy =  np.zeros((maxBitSize, len(fractBitsList)))\n",
    "        #iterates over specified numberfs of fractional bits, and specified number of overall bits for each\n",
    "        for fractBitsIdx in range(len(fractBitsList)):\n",
    "            for bits in range(max(fractBitsList[fractBitsIdx], 1), maxBitSize + 1):\n",
    "                #initializes a new container for all weights of the current layer\n",
    "                newLayer = []\n",
    "                #iterates over all sets of weights in layer (needed, because the list of all weights has inhomogenus shape, so numpy cant handle it)\n",
    "                for weightCount in range(len(originalLayer.get_weights())):\n",
    "                    #append the quantized weights to new layer\n",
    "                    newLayer.append(fixedPointConversion(copy.deepcopy(originalLayer.get_weights()[weightCount]), bits, fractBitsList[fractBitsIdx]))\n",
    "                #sets the new layer\n",
    "                model.layers[currentLayer].set_weights(newLayer)\n",
    "                #tests the new accuracy and stores it in a matrix\n",
    "                test_loss, test_acc = model.evaluate(testImages,  testLabels, verbose=0)\n",
    "                layerAccuracy[bits-1][fractBitsIdx] = test_acc        \n",
    "\n",
    "        #detecting the best accuracy by tolerance\n",
    "        #ToDo: optimize the function picking the best sizes\n",
    "        bestAccuracy = {\"bitIdx\" : 0, \"fractIdx\" : 0, \"accuracy\" : 0}\n",
    "        for bits in range(maxBitSize):\n",
    "            for fractBits in range(len(fractBitsList)):\n",
    "                if ((layerAccuracy[bits][fractBits] - tolerancePerLayer) > bestAccuracy[\"accuracy\"]):\n",
    "                    bestAccuracy[\"bitIdx\"] = bits\n",
    "                    bestAccuracy[\"fractIdx\"] = fractBits\n",
    "                    bestAccuracy[\"accuracy\"] = layerAccuracy[bits][fractBits]\n",
    "        \n",
    "        #set the final new weights\n",
    "        if (bestAccuracy[\"bitIdx\"] > 0):\n",
    "            newLayer = []\n",
    "            for weightCount in range(len(originalLayer.get_weights())):\n",
    "                newLayer.append(fixedPointConversion(copy.deepcopy(originalLayer.get_weights()[weightCount]), bestAccuracy[\"bitIdx\"] + 1, fractBitsList[bestAccuracy[\"fractIdx\"]]))\n",
    "            model.layers[currentLayer].set_weights(newLayer)\n",
    "        print(\"Layer: \" + str(currentLayer) + \" bits: \" + str(bestAccuracy[\"bitIdx\"] + 1) + \" fractional Bits: \" + str(fractBitsList[bestAccuracy[\"fractIdx\"]]) + \" Accuracy: \")\n",
    "        averageStorageUse.append(bestAccuracy[\"bitIdx\"] + 1)\n",
    "        test_loss, test_acc = model.evaluate(testImages,  testLabels, verbose=0)\n",
    "        print (test_acc)\n",
    "        accuracyDeveloptment.append(test_acc)\n",
    "\n",
    "plt.xlabel(\"Quantized Layer\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0, 1])\n",
    "plt.plot(accuracyDeveloptment)\n",
    "plt.show()\n",
    "\n",
    "print(\"average storage use: \" + str(np.mean(averageStorageUse)) + \" Bits\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
